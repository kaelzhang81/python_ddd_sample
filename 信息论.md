# 信息论处理的是客观世界中的不确定性

不确定性才是客观世界的本质属性。

## 信息论的诞生
1948，香农的《通信的数学理论》---给出对信息这一定性概念的定量分析方法。
“通信的基本问题是在一点精确地或近似地复现在另一点所选取的消息。消息通常有意义，即根据某种体系，消息本身指向或关联着物理上或概念上的特定实体。但消息的语义含义与工程问题无关，重要的是一条消息来自于一个所有可能的消息的集合。”

信息论使用“信息熵”的概念，对单个信源的信息量和通信中传递信息的数量与效率等问题做出了解释，并在世界的不确定性和信息的可测量性之间搭建起一座桥梁。

信息的载体是消息，不同的消息带来的信息即使在直观上也不尽相同。（例如：中国足球夺冠比乒乓球夺冠信息要大得多）以不确定性来度量信息是一种合理的方式。不确定性越大的消息可能性越小，其提供的信息量就越大。

## 熵
“熵”源于冯诺依曼---一个系统内在的混乱程度。

如果事件A发生的概率为p(A)，则这个事件的自信息量的定义为：
单个事件的自信息量可以计算包含多个符号的信源的信息熵，如果一个离散信源X包含n个符号，每个符号ai的取值为p（ai），则X的信息熵为

信息熵描述了信源每发送一个符号所提供的平均信息量，是信源总体信息测度的均值。

# 条件熵和信息增益是分类问题中的重要参数

# KL散度用于描述两个不同概率分布之间的差异

# 最大熵原理是分类问题汇总的常用准则
